<?xml version="1.0" encoding="UTF-8"?>

<alvisnlp-plan id="export">


  <!--
  ///////////////////////////////////////////////////////////////////////////////////////
  //
  //  FCU
  //
  ///////////////////////////////////////////////////////////////////////////////////////
  -->


  <!-- save exctracted terms -->
  <export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>fcu.csv</corpusFile>
    <lines>documents.sections.(layer:fcu)</lines>
    <headers>"bsv","type","context","word","prefLabel","context","location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- type of document  -->
      section.@name;
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      @skos-prefLabel;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)
    </columns>
    <trueCSV/>
  </export>


  <fcu_vocab class="AggregateValues">
    <entries>documents.sections.layer:fcu</entries>
    <key>@form</key>
    <outFile>output/fcu.txt</outFile>
  </fcu_vocab>
  <!--
  ///////////////////////////////////////////////////////////////////////////////////////
  //
  //  Conjunctions
  //
  ///////////////////////////////////////////////////////////////////////////////////////
  -->

  <conj_export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>conjunctions.csv</corpusFile>
    <lines>documents.sections.layer:conjunctions[inside:fcu]</lines>
    <headers>"bsv","context", "word", "context", "location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)
    </columns>
    <trueCSV/>
  </conj_export>

  <conj_vocab class="AggregateValues">
    <entries>documents.sections.layer:conjunctions[@match == "fcu"]</entries>
    <key>@form</key>
    <outFile>output/conj.txt</outFile>
  </conj_vocab>

  <conj_vocab_masked class="AggregateValues">
    <entries>documents.sections.layer:conjunctions[@match == "fcu"]</entries>
    <key>str:replace(@form, inside:fcu, "[MASK]")</key>
    <outFile>output/conj_masked.txt</outFile>
  </conj_vocab_masked>


  <!--
  ///////////////////////////////////////////////////////////////////////////////////////
  //
  //  Stages
  //
  ///////////////////////////////////////////////////////////////////////////////////////
  -->


  <bbch_export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>bbch.csv</corpusFile>
    <lines>documents.sections.layer:bbch</lines>
    <headers>"bsv","context", "word", "context", "location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)

    </columns>
    <trueCSV/>
  </bbch_export>


  <bbch_vocab class="AggregateValues">
    <entries>documents.sections.layer:bbch</entries>
    <key>@form</key>
    <outFile>output/bbch.txt</outFile>
  </bbch_vocab>


  <!--
  ///////////////////////////////////////////////////////////////////////////////////////
  //
  //  Save tokenized words
  //
  ///////////////////////////////////////////////////////////////////////////////////////
  -->


  <!-- all tokenized words in corpus -->
  <vocabulary class="AggregateValues">
    <entries>documents.sections.layer:words</entries>
    <key>@lemma</key>
    <outFile>output/words.txt</outFile>
  </vocabulary>



  <!--
  ///////////////////////////////////////////////////////////////////////////////////////
  //
  //  Save scores
  //
  ///////////////////////////////////////////////////////////////////////////////////////
  -->



  <tf_idf href="modules/scores.plan">
    <outFile>output/tfidf.csv</outFile>
    <keywords>sections.layer:fcu</keywords>
    <scoreFunction>tfidf</scoreFunction>
  </tf_idf>

  <freq href="modules/scores.plan">
    <outFile>output/freq.csv</outFile>
    <keywords>sections.layer:fcu</keywords>
    <scoreFunction type="freq"/>
  </freq>

  <freqrel href="modules/scores.plan">
    <outFile>output/freq_rel.csv</outFile>
    <keywords>sections.layer:fcu</keywords>
    <scoreFunction type="freq" relative="true"/>
  </freqrel>

  <bm25 href="modules/scores.plan">
    <outFile>output/bm25.csv</outFile>
    <keywords>sections.layer:fcu</keywords>
    <scoreFunction type ="bm25" k1="1.2" b="0.75"/>
  </bm25>


  <!-- TODO II. topic modelling  -->

</alvisnlp-plan>
