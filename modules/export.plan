<?xml version="1.0" encoding="UTF-8"?>

<alvisnlp-plan id="export">

  <!-- save exctracted terms -->
  <export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>export.csv</corpusFile>
    <lines>documents.sections.(layer:fcu | layer:stages)</lines>
    <headers>"bsv","type","context","word","prefLabel","context","location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- type of document  -->
      section.@name;
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      @skos-prefLabel;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)
    </columns>
    <trueCSV/>
  </export>


  <conj_export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>patterns.csv</corpusFile>
    <lines>documents.sections.(layer:conjunctions)</lines>
    <headers>"bsv","context", "word", "context", "location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)
    </columns>
    <trueCSV/>
  </conj_export>

  <bbch_export class="TabularExport">
    <outDir>output</outDir>
    <corpusFile>bbch.csv</corpusFile>
    <lines>documents.sections.(layer:bbch)</lines>
    <headers>"bsv","context", "word", "context", "location","features"</headers>
    <columns separator=";">
      <!-- short document id  -->
      str:replace(str:basename(section.document.@id), ".html", "");
      <!-- context before  -->
      str:normalizeSpace(str:sub(section.contents, m:max(0, start - 20), start));
      <!-- extracted term  -->
      @form;
      <!-- context after  -->
      str:normalizeSpace(str:sub(section.contents, end, m:min(end + 20, str:len(section.contents))));
      <!-- location  -->
      start ^ "-" ^ end;
      <!-- features  -->
      str:join:', '(nav:features, @key ^ "=" ^ @value)
    </columns>
    <trueCSV/>
  </bbch_export>


  <!-- all tokenized words in corpus -->
  <vocabulary class="AggregateValues">
    <entries>documents.sections.layer:words</entries>
    <key>@lemma</key>
    <outFile>output/words.txt</outFile>
  </vocabulary>


  <!-- TODO II. divide score to simply tf -->
  <!-- calculate tf-idf -->
  <tdidf class="KeywordsSelector">
    <outFile>output/tfidf.csv</outFile>
    <keywords>sections.layer:fcu</keywords>
    <documentId>str:replace(str:basename(@id), ".html", "")</documentId>
    <keywordForm>@skos-prefLabel</keywordForm>
    <scoreThreshold>-1000</scoreThreshold>
    <scoreFunction>tfidf</scoreFunction>
  </tdidf>


  <!-- TODO III. topic modelling  -->
</alvisnlp-plan>



<!--
before:words{-3}.@form;
before:words{-2}.@form;
before:words{-1}.@form;
after:words{0}.@form;
after:words{1}.@form;
after:words{2}.@form;

-->

<!-- features  ;
str:join:' '(inside:words, @lemma)
-->
